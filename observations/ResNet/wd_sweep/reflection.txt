2023/07/03

Changing the seed from 1 to 0 resulted in the dramatic improvement of trial 
(depth 9, wd 5e-4) - so much so that it went from breaking the functional form
to making it steeper! Now, the actual *research* part consists of 
understanding why it's [not] working, and fixing it when it's broken. Pulling
these threads is what allows a highly productive researcher at OpenAI to
identify and eliminate any irregularities, ensuring stability in results,
thereby producing a highly predictive functional form.

The answer lies in the learning curves of the variant trials. We must plot
the experiment in wandb (possibly including telemetry i.e. gradient norms), 
and analyze the results to understand the cause of variation. In doing so, we
can systematically construct a model with good scaling laws in addition to
simply executing the research well.

Observations
----

Seed 1


test/error_rate at epoch 50 seems to show the expected results. The error
rates decrease as depth is scaled: 22.6%, 22%, 21.9%, 21.7%, 20.6%, for depths
2, 3, 4, 5, 7, 9.

It's worth noting that the higher the depth, the worse the first epoch's error
rate is. This is significantly exacerbated for depth 9. Though, as should
logically follow based on the end result, the acceleration of the improvement
of the higher depth's error rate is also greater.

After computing a running average smoothing on the test/loss graph, the
expected trend is shown towards the end of training. Loss scores are 0.74,
0.6, 0.55, 0.53, 0.52 for depths 2, 3, 5, 7, 9. Again, deeper architectures
start off worse and progressively get better through the duration of training.

Finally, though depth 9 establishes itself as the best architecture at the
final step, it often finds itself at odds with depth 7 such as from steps
23k-23.5k.

Seed 0

test/loss reflects the common trend in which loss starts out worse but 
inevitably improves as depth is scaled. This time depth 9 doesn't end
as the best test loss, instead getting replaced by depth 2! While previously
the best, it along with every depth except 2 gets worse towards the final
steps. Depth 9 is much more consistently better than other architectures up
until this point however, only getting outpaced by depth 7 between 20.2k-20.6k
and 22.1k-22.5k.
